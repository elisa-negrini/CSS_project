{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3987ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎥 YouTube Data Scraper - Avvio raccolta dati...\n",
      "🔍 Query: 'war ukraine'\n",
      "📅 Range temporale: 2025-05-01T00:00:00Z -> 2025-05-10T23:59:59Z\n",
      "✅ YouTube API inizializzata con successo!\n",
      "\n",
      "📄 Pagina 1 - Ricerca video...\n",
      "   📹 Trovati 50 video\n",
      "   🎬 Processando: Ukrainian forces eliminated 14 Russian soldiers at...\n",
      "   🎬 Processando: Trump&#39;s message to Russia and Ukraine: Get thi...\n",
      "   🎬 Processando: Spectacular Failure: 4 VECTORS, 46 ASSAULTS, ZERO ...\n",
      "   🎬 Processando: F-16 &amp; Mirage Pilots Are Doing Something UNBEL...\n",
      "   🎬 Processando: European leaders pressure Russia over 30-day Ukrai...\n",
      "   🎬 Processando: Polina Kudermetova supports war against Ukraine...\n",
      "   🎬 Processando: Moment Ukraine&#39;s drones hit Russian targets as...\n",
      "   🎬 Processando: Unbelievable MAD MAX Tactics Used by Ukraine to CR...\n",
      "   🎬 Processando: Russia ‘cannot survive’ Putin’s war in Ukraine | F...\n",
      "   🎬 Processando: Ukraine’s Secret War Strategy Is Working...\n",
      "   🎬 Processando: Putin RAGES as U.S. FUNDS Ukraine’s WEAPONS Surge...\n",
      "   🎬 Processando: Xi Joins Putin At Victory Day As Russia Parades Uk...\n",
      "   🎬 Processando: &#39;Xi Jinping has officially come off the fence&...\n",
      "   🎬 Processando: #Russia parades drones during #VictoryDayparade, u...\n",
      "   🎬 Processando: 3 Ukrainian fighters against attacking Russian pla...\n",
      "   🎬 Processando: &#39;Xi Jinping has officially come off the fence&...\n",
      "   🎬 Processando: Two heroic Ukrainian soldiers defeat FIVE Russians...\n",
      "   🎬 Processando: Russia Victory Parade LIVE | Putin’s Military Powe...\n",
      "   🎬 Processando: BREAKING: Trump calls for 30-day ceasefire in Russ...\n",
      "   🎬 Processando: From Russian Motorbike Assaults to Ukraine’s New D...\n",
      "   🎬 Processando: Ukraine: Stillstand an der Front – Militärökonom K...\n",
      "   🎬 Processando: Update from Ukraine | Great! Ukraine Pushed Ruzzia...\n",
      "   🎬 Processando: Putin MELTS DOWN as Ukraine’s Drones HIT Moscow HA...\n",
      "   🎬 Processando: Abrams and Leopard vs. Russian Tank T-90M. Western...\n",
      "   🎬 Processando: Russia urgently &quot;cancels May 9&quot; after ma...\n",
      "   🎬 Processando: Russia-Ukraine War: &#39;Russia Asking For Too Muc...\n",
      "   🎬 Processando: Ukraine drones hunt down Russian troops as Putin b...\n",
      "   🎬 Processando: Trump warns of &#39;decisions&#39; that may need t...\n",
      "   🎬 Processando: War Evolves: Combat Divers &amp; Ukraine’s Frontli...\n",
      "   🎬 Processando: Putin’s war machine ‘burns’ as Russia strips front...\n",
      "   🎬 Processando: Soldier pins down enemy targets with RPG fire...\n",
      "   🎬 Processando: Biden accuses Trump of appeasement of Russia...\n",
      "      ℹ️ Commenti disabilitati per video jOMM6bdEyBA\n",
      "   🎬 Processando: Ukrainian drones strike key Moscow airfield in maj...\n",
      "   🎬 Processando: Update from Ukraine | Crazy Biggest Strike on Ruzz...\n",
      "   🎬 Processando: Ukraine sniper ELIMINATES Russian soldiers as they...\n",
      "   🎬 Processando: Putin BETRAYED! US Sends MASSIVE Missile System to...\n",
      "   🎬 Processando: Turkey Has Had ENOUGH! Erdogan STEPS IN to End Rus...\n",
      "   🎬 Processando: Ukrainian drones attack Moscow, halting flights ah...\n",
      "   🎬 Processando: Russian military armaments devastated by Ukraine b...\n",
      "   🎬 Processando: Russian drones hit Kharkiv after Ukrainian attacks...\n",
      "   🎬 Processando: Russia-Ukraine War LIVE: Massive Attack! Russian P...\n",
      "   🎬 Processando: UK overwhelmed by Russian missiles in war game sim...\n",
      "   🎬 Processando: Russia Launches Multi-Directional Offensives In Uk...\n",
      "   🎬 Processando: Courage Turned Catastrophe: Russian Soldier&#39;s ...\n",
      "   🎬 Processando: Former Head of MI6: How The Ukraine War Will End &...\n",
      "   🎬 Processando: Update from Ukraine | Crazy! Ukraine Revenge | Big...\n",
      "   🎬 Processando: Russia preparing for large-scale attacks on 3 regi...\n",
      "   🎬 Processando: War in the Black Sea: Ukrainian defenders destroy ...\n",
      "   🎬 Processando: Amid Zelensky Threat To Attack World Leaders In Ru...\n",
      "   🎬 Processando: Russian commanders shot soldiers who refused to fi...\n",
      "   ✅ 50 video, 1918 commenti raccolti\n",
      "   📊 Totale: 50 video, 1918 commenti\n",
      "   📈 Quota stimata usata: 151/10000\n",
      "\n",
      "📄 Pagina 2 - Ricerca video...\n",
      "   📹 Trovati 26 video\n",
      "   🎬 Processando: Russia launches deadly strike on Ukraine after US ...\n",
      "   🎬 Processando: Retired US General SHOCKS Everyone - Russia’s Defe...\n",
      "   🎬 Processando: The Shocking Truth About Russia’s Military Depende...\n",
      "   🎬 Processando: Ukraine unleashes Brit missiles in heaviest blitz ...\n",
      "   🎬 Processando: Russia-Ukraine War: Kharkiv Devastated by Russian ...\n",
      "   🎬 Processando: Update from Ukraine | Wow! Ukraine goes all in Str...\n",
      "   🎬 Processando: This Is the Life of Ukrainian Soldiers on the Fron...\n",
      "   🎬 Processando: Russia-Ukraine War: Moscow Views Minerals Deal A D...\n",
      "   🎬 Processando: Why Ukraine War&#39;s Deadly Drones Are Now Flying...\n",
      "   🎬 Processando: Still Think Russia Is Defeating Ukraine? Watch Thi...\n",
      "   🎬 Processando: US &#39;pulls out of Ukraine peace talks&#39; with...\n",
      "   🎬 Processando: 24 Russian soldiers are dead - Ukrainian drones’ o...\n",
      "   🎬 Processando: Vance: War in Ukraine Not Ending &#39;Anytime Soon...\n",
      "   🎬 Processando: Explosions tear through Russian airbase as Ukraine...\n",
      "   🎬 Processando: MASSIVE EXPLOSIONS IN CRIMEA, US GOES BALLISTIC ON...\n",
      "   🎬 Processando: Horrible!! Ukrainian brigade blow up Russian infan...\n",
      "   🎬 Processando: Ukraine DECLARES VICTORY as Russia’s Pokrovsk Plan...\n",
      "   🎬 Processando: POV: ʼGuys, I’m 300ʼ. Ukraine’s Mopping-Up Mission...\n",
      "   🎬 Processando: Putin Is FURIOUS! Ukraine Gets 6 Million Shells! 1...\n",
      "   🎬 Processando: Can Ukraine still win the war against Russia? | BB...\n",
      "   🎬 Processando: Pakistan-India war in 2025 ? #countryballs #UA_bal...\n",
      "   🎬 Processando: Russia-Ukraine War: Russian Drones Damage Building...\n",
      "   🎬 Processando: Putin Bashes Europe Over Ukraine War, Gives This M...\n",
      "   🎬 Processando: Update from Ukraine | Zelenskyy wants to Strike Ru...\n",
      "   🎬 Processando: Putin FURIOUS After French Missiles Leave Forces i...\n",
      "   🎬 Processando: Mass &quot;suicide&quot; of Russians on motorcycle...\n",
      "   ✅ 26 video, 1356 commenti raccolti\n",
      "   📊 Totale: 76 video, 3274 commenti\n",
      "   📈 Quota stimata usata: 278/10000\n",
      "   ℹ️ Non ci sono più pagine disponibili\n",
      "\n",
      "💾 Salvataggio finale in youtube_war_ukraine_5.json...\n",
      "\n",
      "🎉 COMPLETATO!\n",
      "📊 Statistiche finali:\n",
      "   📄 Pagine processate: 2\n",
      "   🎬 Video totali: 76\n",
      "   💬 Commenti totali: 3274\n",
      "   📈 Quota stimata usata: 278/10000 (2.8%)\n",
      "   📄 File salvato: youtube_war_ukraine_5.json\n",
      "   ⏱️ Media commenti/video: 43.1\n",
      "\n",
      "✨ Raccolta completata!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- Configuration ---\n",
    "API_KEY = \"AIzaSyBlUpDZZ4gYI__pCKaI-I-XTiq2q_KCsQY\"  # Inserisci la tua API key nel file .env\n",
    "query = 'war ukraine'  # Puoi anche usare 'zelensky trump' per AND search\n",
    "max_results_per_search = 50  # Max 50 per richiesta\n",
    "max_videos = 2000  # Totale video da processare\n",
    "output_json = 'youtube_war_ukraine_5.json'\n",
    "\n",
    "# --- FILTRI TEMPORALI ---\n",
    "# Puoi impostare range temporali specifici (formato ISO 8601: YYYY-MM-DDTHH:MM:SSZ)\n",
    "published_after = '2025-05-01T00:00:00Z'  # Inizio range\n",
    "published_before = '2025-05-10T23:59:59Z'  # Fine range\n",
    "\n",
    "# --- SETTINGS ---\n",
    "request_delay = 1.0  # Secondi tra le richieste per rispettare rate limits\n",
    "comment_score_min = 5  # Score minimo per i commenti\n",
    "max_comments_per_video = 200  # Max commenti per video per risparmiare quota\n",
    "\n",
    "def initialize_youtube_api():\n",
    "    \"\"\"Inizializza il client YouTube API\"\"\"\n",
    "    if not API_KEY:\n",
    "        print(\"❌ Errore: YOUTUBE_API_KEY non trovata nel file .env\")\n",
    "        exit(1)\n",
    "    \n",
    "    try:\n",
    "        youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "        print(\"✅ YouTube API inizializzata con successo!\")\n",
    "        return youtube\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Errore nell'inizializzare YouTube API: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "def search_videos(youtube, query, published_after=None, published_before=None, max_results=50, page_token=None):\n",
    "    \"\"\"Cerca video con filtri temporali\"\"\"\n",
    "    try:\n",
    "        search_params = {\n",
    "            'q': query,\n",
    "            'part': 'id,snippet',\n",
    "            'type': 'video',\n",
    "            'maxResults': max_results,\n",
    "            'order': 'date',  # Ordina per data\n",
    "            'regionCode': 'US'  # Puoi cambiare in 'IT' per risultati italiani\n",
    "        }\n",
    "        \n",
    "        # Aggiungi filtri temporali se specificati\n",
    "        if published_after:\n",
    "            search_params['publishedAfter'] = published_after\n",
    "        if published_before:\n",
    "            search_params['publishedBefore'] = published_before\n",
    "        if page_token:\n",
    "            search_params['pageToken'] = page_token\n",
    "            \n",
    "        response = youtube.search().list(**search_params).execute()\n",
    "        return response\n",
    "    \n",
    "    except HttpError as e:\n",
    "        print(f\"❌ Errore HTTP nella ricerca: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Errore generico nella ricerca: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_video_details(youtube, video_ids):\n",
    "    \"\"\"Ottieni dettagli dei video (statistiche, durata, etc.)\"\"\"\n",
    "    try:\n",
    "        response = youtube.videos().list(\n",
    "            part='statistics,contentDetails,snippet',\n",
    "            id=','.join(video_ids)\n",
    "        ).execute()\n",
    "        return response\n",
    "    except HttpError as e:\n",
    "        print(f\"❌ Errore nell'ottenere dettagli video: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_video_comments(youtube, video_id, max_results=100):\n",
    "    \"\"\"Ottieni commenti di un video con paginazione\"\"\"\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "    \n",
    "    try:\n",
    "        while len(comments) < max_results:\n",
    "            # Calcola quanti commenti mancano\n",
    "            remaining = max_results - len(comments)\n",
    "            per_page = min(100, remaining)  # YouTube max 100 per richiesta\n",
    "            \n",
    "            request_params = {\n",
    "                'part': 'snippet,replies',\n",
    "                'videoId': video_id,\n",
    "                'maxResults': per_page,\n",
    "                'order': 'relevance',  # Oppure 'time' per cronologico\n",
    "                'textFormat': 'plainText'\n",
    "            }\n",
    "            \n",
    "            if next_page_token:\n",
    "                request_params['pageToken'] = next_page_token\n",
    "            \n",
    "            response = youtube.commentThreads().list(**request_params).execute()\n",
    "            \n",
    "            for item in response['items']:\n",
    "                comment = item['snippet']['topLevelComment']['snippet']\n",
    "                \n",
    "                # Filtra per score minimo\n",
    "                if comment.get('likeCount', 0) >= comment_score_min:\n",
    "                    comment_data = {\n",
    "                        'author': comment.get('authorDisplayName', '[Unknown]'),\n",
    "                        'text': comment.get('textDisplay', ''),\n",
    "                        'like_count': comment.get('likeCount', 0),\n",
    "                        'published_at': comment.get('publishedAt', ''),\n",
    "                        'updated_at': comment.get('updatedAt', '')\n",
    "                    }\n",
    "                    \n",
    "                    # Aggiungi replies se presenti\n",
    "                    if 'replies' in item:\n",
    "                        replies = []\n",
    "                        for reply in item['replies']['comments']:\n",
    "                            reply_snippet = reply['snippet']\n",
    "                            if reply_snippet.get('likeCount', 0) >= comment_score_min:\n",
    "                                replies.append({\n",
    "                                    'author': reply_snippet.get('authorDisplayName', '[Unknown]'),\n",
    "                                    'text': reply_snippet.get('textDisplay', ''),\n",
    "                                    'like_count': reply_snippet.get('likeCount', 0),\n",
    "                                    'published_at': reply_snippet.get('publishedAt', '')\n",
    "                                })\n",
    "                        comment_data['replies'] = replies\n",
    "                    \n",
    "                    comments.append(comment_data)\n",
    "            \n",
    "            # Controlla se ci sono altre pagine\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "                \n",
    "            # Pausa tra le richieste\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    except HttpError as e:\n",
    "        if 'commentsDisabled' in str(e):\n",
    "            print(f\"      ℹ️ Commenti disabilitati per video {video_id}\")\n",
    "        else:\n",
    "            print(f\"      ⚠️ Errore nell'ottenere commenti per {video_id}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ⚠️ Errore generico commenti per {video_id}: {e}\")\n",
    "    \n",
    "    return comments\n",
    "\n",
    "def main():\n",
    "    print(\"🎥 YouTube Data Scraper - Avvio raccolta dati...\")\n",
    "    print(f\"🔍 Query: '{query}'\")\n",
    "    print(f\"📅 Range temporale: {published_after} -> {published_before}\")\n",
    "    \n",
    "    # Inizializza API\n",
    "    youtube = initialize_youtube_api()\n",
    "    \n",
    "    all_data = []\n",
    "    total_videos = 0\n",
    "    total_comments = 0\n",
    "    next_page_token = None\n",
    "    page_number = 1\n",
    "    \n",
    "    # Stima quota usage\n",
    "    estimated_quota = 0\n",
    "    \n",
    "    while total_videos < max_videos:\n",
    "        print(f\"\\n📄 Pagina {page_number} - Ricerca video...\")\n",
    "        \n",
    "        # Calcola quanti video mancano\n",
    "        remaining_videos = max_videos - total_videos\n",
    "        search_limit = min(max_results_per_search, remaining_videos)\n",
    "        \n",
    "        # Cerca video\n",
    "        search_response = search_videos(\n",
    "            youtube, query, published_after, published_before, \n",
    "            search_limit, next_page_token\n",
    "        )\n",
    "        \n",
    "        if not search_response or not search_response.get('items'):\n",
    "            print(\"   ℹ️ Nessun video trovato o fine risultati\")\n",
    "            break\n",
    "        \n",
    "        estimated_quota += 100  # Costo search\n",
    "        videos = search_response['items']\n",
    "        print(f\"   📹 Trovati {len(videos)} video\")\n",
    "        \n",
    "        # Ottieni dettagli video (statistiche)\n",
    "        video_ids = [video['id']['videoId'] for video in videos]\n",
    "        video_details_response = get_video_details(youtube, video_ids)\n",
    "        estimated_quota += 1  # Costo video details\n",
    "        \n",
    "        # Crea mappa per accesso rapido ai dettagli\n",
    "        video_details_map = {}\n",
    "        if video_details_response:\n",
    "            for detail in video_details_response['items']:\n",
    "                video_details_map[detail['id']] = detail\n",
    "        \n",
    "        page_videos = 0\n",
    "        page_comments = 0\n",
    "        \n",
    "        # Processa ogni video\n",
    "        for video in videos:\n",
    "            video_id = video['id']['videoId']\n",
    "            snippet = video['snippet']\n",
    "            \n",
    "            # Ottieni dettagli aggiuntivi\n",
    "            details = video_details_map.get(video_id, {})\n",
    "            stats = details.get('statistics', {})\n",
    "            content_details = details.get('contentDetails', {})\n",
    "            \n",
    "            print(f\"   🎬 Processando: {snippet['title'][:50]}...\")\n",
    "            \n",
    "            # Ottieni commenti\n",
    "            comments = get_video_comments(youtube, video_id, max_comments_per_video)\n",
    "            estimated_quota += max(1, len(comments) // 100)  # Stima quota commenti\n",
    "            \n",
    "            # Costruisci record video\n",
    "            video_record = {\n",
    "                'page_number': page_number,\n",
    "                'video_id': video_id,\n",
    "                'title': snippet['title'],\n",
    "                'description': snippet.get('description', '')[:500],  # Primi 500 char\n",
    "                'channel_title': snippet['channelTitle'],\n",
    "                'channel_id': snippet['channelId'],\n",
    "                'published_at': snippet['publishedAt'],\n",
    "                'thumbnail_url': snippet['thumbnails']['high']['url'] if 'high' in snippet['thumbnails'] else '',\n",
    "                \n",
    "                # Statistiche\n",
    "                'view_count': int(stats.get('viewCount', 0)),\n",
    "                'like_count': int(stats.get('likeCount', 0)),\n",
    "                'comment_count': int(stats.get('commentCount', 0)),\n",
    "                'duration': content_details.get('duration', ''),\n",
    "                \n",
    "                # Commenti raccolti\n",
    "                'comments': comments,\n",
    "                'comments_collected': len(comments)\n",
    "            }\n",
    "            \n",
    "            all_data.append(video_record)\n",
    "            page_videos += 1\n",
    "            page_comments += len(comments)\n",
    "            \n",
    "            # Piccola pausa tra i video\n",
    "            time.sleep(0.2)\n",
    "        \n",
    "        total_videos += page_videos\n",
    "        total_comments += page_comments\n",
    "        \n",
    "        print(f\"   ✅ {page_videos} video, {page_comments} commenti raccolti\")\n",
    "        print(f\"   📊 Totale: {total_videos} video, {total_comments} commenti\")\n",
    "        print(f\"   📈 Quota stimata usata: {estimated_quota}/10000\")\n",
    "        \n",
    "        # Controlla se ci sono altre pagine\n",
    "        next_page_token = search_response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            print(\"   ℹ️ Non ci sono più pagine disponibili\")\n",
    "            break\n",
    "        \n",
    "        page_number += 1\n",
    "        \n",
    "        # Pausa tra le pagine per rispettare rate limits\n",
    "        time.sleep(request_delay)\n",
    "        \n",
    "        # Salva progressi ogni 5 pagine\n",
    "        if page_number % 5 == 0:\n",
    "            print(f\"   💾 Salvataggio progressi...\")\n",
    "            with open(f\"temp_{output_json}\", 'w', encoding='utf-8') as f:\n",
    "                json.dump(all_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Salvataggio finale\n",
    "    print(f\"\\n💾 Salvataggio finale in {output_json}...\")\n",
    "    with open(output_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Statistiche finali\n",
    "    print(f\"\\n🎉 COMPLETATO!\")\n",
    "    print(f\"📊 Statistiche finali:\")\n",
    "    print(f\"   📄 Pagine processate: {page_number}\")\n",
    "    print(f\"   🎬 Video totali: {total_videos}\")\n",
    "    print(f\"   💬 Commenti totali: {total_comments}\")\n",
    "    print(f\"   📈 Quota stimata usata: {estimated_quota}/10000 ({(estimated_quota/10000)*100:.1f}%)\")\n",
    "    print(f\"   📄 File salvato: {output_json}\")\n",
    "    \n",
    "    if total_videos > 0:\n",
    "        print(f\"   ⏱️ Media commenti/video: {total_comments/total_videos:.1f}\")\n",
    "    \n",
    "    # Rimuovi file temporaneo\n",
    "    temp_file = f\"temp_{output_json}\"\n",
    "    if os.path.exists(temp_file):\n",
    "        os.remove(temp_file)\n",
    "        print(f\"🗑️ File temporaneo rimosso\")\n",
    "    \n",
    "    print(f\"\\n✨ Raccolta completata!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c16176ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎥 Numero totale di video: 76\n",
      "💬 Numero totale di commenti raccolti: 3274\n",
      "👀 Visualizzazioni totali: 37,288,351\n",
      "👍 Like totali: 734,310\n",
      "📊 Media commenti per video: 43.1\n",
      "📊 Media visualizzazioni per video: 490,636\n",
      "\n",
      "🧾 DataFrame creato con 4596 righe\n",
      "📊 Colonne disponibili: ['video_id', 'video_title', 'channel_title', 'channel_id', 'video_published_at', 'video_view_count', 'video_like_count', 'video_comment_count', 'video_duration', 'video_description', 'comment_author', 'comment_text', 'comment_like_count', 'comment_published_at', 'comment_updated_at', 'comment_replies_count', 'is_reply', 'video_age_days', 'comment_length', 'video_duration_seconds', 'video_duration_minutes']\n",
      "\n",
      "📋 Esempio del DataFrame:\n",
      "                                         video_title  \\\n",
      "0  Ukrainian forces eliminated 14 Russian soldier...   \n",
      "1  Trump&#39;s message to Russia and Ukraine: Get...   \n",
      "2  Spectacular Failure: 4 VECTORS, 46 ASSAULTS, Z...   \n",
      "3  Spectacular Failure: 4 VECTORS, 46 ASSAULTS, Z...   \n",
      "4  Spectacular Failure: 4 VECTORS, 46 ASSAULTS, Z...   \n",
      "\n",
      "                       channel_title            comment_author  \\\n",
      "0                  US Military Rifle                      None   \n",
      "1                    KMPH FOX26 NEWS                      None   \n",
      "2  RFU News — Reporting from Ukraine                      @RFU   \n",
      "3  RFU News — Reporting from Ukraine           @Curlyhowardfan   \n",
      "4  RFU News — Reporting from Ukraine  @The-Droll-and-LazyJoker   \n",
      "\n",
      "   comment_like_count  is_reply  \n",
      "0                 NaN     False  \n",
      "1                 NaN     False  \n",
      "2                63.0     False  \n",
      "3               196.0     False  \n",
      "4                16.0      True  \n",
      "\n",
      "📈 Statistiche rapide:\n",
      "   🎬 Video unici: 76\n",
      "   📺 Canali unici: 33\n",
      "   👤 Autori commenti unici: 3908\n",
      "   💬 Commenti principali: 3283\n",
      "   🔄 Risposte: 1313\n",
      "   👍 Like medio per commento: 42.1\n",
      "   👍 Commento con più like: 3606.0\n",
      "\n",
      "🏆 Top 5 canali per numero di video:\n",
      "   📺 The Sun: 10 video\n",
      "   📺 The Military Show: 9 video\n",
      "   📺 Kanal13: 7 video\n",
      "   📺 WION: 6 video\n",
      "   📺 Denys Davydov: 5 video\n",
      "\n",
      "💾 DataFrame salvato come: youtube_war_ukraine_data_5.csv\n",
      "💾 Solo commenti salvati come: youtube_war_ukraine_comments_only_5.csv\n",
      "💾 Summary video salvato come: youtube_war_ukraine_video_summary_5.csv\n",
      "\n",
      "✨ Elaborazione completata!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Caricamento del file JSON ---\n",
    "with open('youtube_war_ukraine_5.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# --- Statistiche ---\n",
    "num_videos = len(data)\n",
    "num_comments = sum(video['comments_collected'] for video in data)\n",
    "total_views = sum(video['view_count'] for video in data)\n",
    "total_likes = sum(video['like_count'] for video in data)\n",
    "\n",
    "print(f\"🎥 Numero totale di video: {num_videos}\")\n",
    "print(f\"💬 Numero totale di commenti raccolti: {num_comments}\")\n",
    "print(f\"👀 Visualizzazioni totali: {total_views:,}\")\n",
    "print(f\"👍 Like totali: {total_likes:,}\")\n",
    "\n",
    "if num_videos > 0:\n",
    "    print(f\"📊 Media commenti per video: {num_comments/num_videos:.1f}\")\n",
    "    print(f\"📊 Media visualizzazioni per video: {total_views/num_videos:,.0f}\")\n",
    "\n",
    "# --- Creazione del DataFrame ---\n",
    "rows = []\n",
    "\n",
    "for video in data:\n",
    "    video_id = video['video_id']\n",
    "    video_title = video['title']\n",
    "    channel_title = video['channel_title']\n",
    "    channel_id = video['channel_id']\n",
    "    published_at = video['published_at']\n",
    "    view_count = video['view_count']\n",
    "    like_count = video['like_count']\n",
    "    comment_count = video['comment_count']\n",
    "    duration = video['duration']\n",
    "    description = video['description']\n",
    "    \n",
    "    # Se il video non ha commenti, aggiungi comunque una riga per il video\n",
    "    if not video['comments']:\n",
    "        rows.append({\n",
    "            'video_id': video_id,\n",
    "            'video_title': video_title,\n",
    "            'channel_title': channel_title,\n",
    "            'channel_id': channel_id,\n",
    "            'video_published_at': published_at,\n",
    "            'video_view_count': view_count,\n",
    "            'video_like_count': like_count,\n",
    "            'video_comment_count': comment_count,\n",
    "            'video_duration': duration,\n",
    "            'video_description': description[:200] + '...' if len(description) > 200 else description,\n",
    "            \n",
    "            # Campi commento vuoti\n",
    "            'comment_author': None,\n",
    "            'comment_text': None,\n",
    "            'comment_like_count': None,\n",
    "            'comment_published_at': None,\n",
    "            'comment_updated_at': None,\n",
    "            'comment_replies_count': None,\n",
    "            'is_reply': False\n",
    "        })\n",
    "    else:\n",
    "        # Processa ogni commento\n",
    "        for comment in video['comments']:\n",
    "            # Commento principale\n",
    "            rows.append({\n",
    "                'video_id': video_id,\n",
    "                'video_title': video_title,\n",
    "                'channel_title': channel_title,\n",
    "                'channel_id': channel_id,\n",
    "                'video_published_at': published_at,\n",
    "                'video_view_count': view_count,\n",
    "                'video_like_count': like_count,\n",
    "                'video_comment_count': comment_count,\n",
    "                'video_duration': duration,\n",
    "                'video_description': description[:200] + '...' if len(description) > 200 else description,\n",
    "                \n",
    "                # Dati commento\n",
    "                'comment_author': comment['author'],\n",
    "                'comment_text': comment['text'],\n",
    "                'comment_like_count': comment['like_count'],\n",
    "                'comment_published_at': comment['published_at'],\n",
    "                'comment_updated_at': comment['updated_at'],\n",
    "                'comment_replies_count': len(comment.get('replies', [])),\n",
    "                'is_reply': False\n",
    "            })\n",
    "            \n",
    "            # Processa le risposte se presenti\n",
    "            if 'replies' in comment and comment['replies']:\n",
    "                for reply in comment['replies']:\n",
    "                    rows.append({\n",
    "                        'video_id': video_id,\n",
    "                        'video_title': video_title,\n",
    "                        'channel_title': channel_title,\n",
    "                        'channel_id': channel_id,\n",
    "                        'video_published_at': published_at,\n",
    "                        'video_view_count': view_count,\n",
    "                        'video_like_count': like_count,\n",
    "                        'video_comment_count': comment_count,\n",
    "                        'video_duration': duration,\n",
    "                        'video_description': description[:200] + '...' if len(description) > 200 else description,\n",
    "                        \n",
    "                        # Dati reply\n",
    "                        'comment_author': reply['author'],\n",
    "                        'comment_text': reply['text'],\n",
    "                        'comment_like_count': reply['like_count'],\n",
    "                        'comment_published_at': reply['published_at'],\n",
    "                        'comment_updated_at': reply.get('updated_at', reply['published_at']),\n",
    "                        'comment_replies_count': 0,  # Le risposte non hanno sotto-risposte\n",
    "                        'is_reply': True\n",
    "                    })\n",
    "\n",
    "# Crea DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# --- Elaborazioni aggiuntive ---\n",
    "if not df.empty:\n",
    "    # Converti le date in datetime per analisi temporali\n",
    "    df['video_published_at'] = pd.to_datetime(df['video_published_at'])\n",
    "    df['comment_published_at'] = pd.to_datetime(df['comment_published_at'])\n",
    "\n",
    "    # Aggiungi questa riga per rimuovere timezone info\n",
    "    df['video_published_at'] = df['video_published_at'].dt.tz_localize(None)\n",
    "    \n",
    "    # Aggiungi colonne derivate utili per l'analisi\n",
    "    df['video_age_days'] = (datetime.now() - df['video_published_at']).dt.days\n",
    "    df['comment_length'] = df['comment_text'].str.len()\n",
    "    \n",
    "    # Estrai durata in secondi (da formato PT1M30S)\n",
    "    def parse_duration(duration_str):\n",
    "        if not duration_str or duration_str == '':\n",
    "            return 0\n",
    "        try:\n",
    "            # Rimuovi PT e splitta per M e S\n",
    "            duration_str = duration_str.replace('PT', '')\n",
    "            minutes = 0\n",
    "            seconds = 0\n",
    "            \n",
    "            if 'H' in duration_str:\n",
    "                parts = duration_str.split('H')\n",
    "                hours = int(parts[0])\n",
    "                duration_str = parts[1]\n",
    "                minutes += hours * 60\n",
    "            \n",
    "            if 'M' in duration_str:\n",
    "                parts = duration_str.split('M')\n",
    "                minutes += int(parts[0])\n",
    "                duration_str = parts[1]\n",
    "            \n",
    "            if 'S' in duration_str:\n",
    "                seconds = int(duration_str.replace('S', ''))\n",
    "            \n",
    "            return minutes * 60 + seconds\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    df['video_duration_seconds'] = df['video_duration'].apply(parse_duration)\n",
    "    df['video_duration_minutes'] = df['video_duration_seconds'] / 60\n",
    "\n",
    "# --- Visualizzazione del DataFrame ---\n",
    "print(f\"\\n🧾 DataFrame creato con {len(df)} righe\")\n",
    "print(f\"📊 Colonne disponibili: {list(df.columns)}\")\n",
    "\n",
    "if not df.empty:\n",
    "    print(\"\\n📋 Esempio del DataFrame:\")\n",
    "    print(df[['video_title', 'channel_title', 'comment_author', 'comment_like_count', 'is_reply']].head())\n",
    "    \n",
    "    print(f\"\\n📈 Statistiche rapide:\")\n",
    "    print(f\"   🎬 Video unici: {df['video_id'].nunique()}\")\n",
    "    print(f\"   📺 Canali unici: {df['channel_id'].nunique()}\")\n",
    "    print(f\"   👤 Autori commenti unici: {df['comment_author'].nunique()}\")\n",
    "    print(f\"   💬 Commenti principali: {len(df[df['is_reply'] == False])}\")\n",
    "    print(f\"   🔄 Risposte: {len(df[df['is_reply'] == True])}\")\n",
    "    \n",
    "    if df['comment_like_count'].notna().any():\n",
    "        print(f\"   👍 Like medio per commento: {df['comment_like_count'].mean():.1f}\")\n",
    "        print(f\"   👍 Commento con più like: {df['comment_like_count'].max()}\")\n",
    "    \n",
    "    # Top canali per numero di video\n",
    "    print(f\"\\n🏆 Top 5 canali per numero di video:\")\n",
    "    top_channels = df.groupby('channel_title')['video_id'].nunique().sort_values(ascending=False).head()\n",
    "    for channel, count in top_channels.items():\n",
    "        print(f\"   📺 {channel}: {count} video\")\n",
    "\n",
    "# --- Salvataggio ---\n",
    "if not df.empty:\n",
    "    # Salva come CSV\n",
    "    csv_filename = 'youtube_war_ukraine_data_5.csv'\n",
    "    df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "    print(f\"\\n💾 DataFrame salvato come: {csv_filename}\")\n",
    "    \n",
    "    # Salva anche un dataset solo commenti (senza video senza commenti)\n",
    "    df_comments_only = df[df['comment_text'].notna()]\n",
    "    if not df_comments_only.empty:\n",
    "        comments_csv = 'youtube_war_ukraine_comments_only_5.csv'\n",
    "        df_comments_only.to_csv(comments_csv, index=False, encoding='utf-8')\n",
    "        print(f\"💾 Solo commenti salvati come: {comments_csv}\")\n",
    "        \n",
    "    # Crea anche un summary dei video\n",
    "    video_summary = df.groupby(['video_id', 'video_title', 'channel_title']).agg({\n",
    "        'video_view_count': 'first',\n",
    "        'video_like_count': 'first',\n",
    "        'video_comment_count': 'first',\n",
    "        'video_duration_minutes': 'first',\n",
    "        'comment_like_count': ['count', 'sum', 'mean'],\n",
    "        'video_published_at': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten column names\n",
    "    video_summary.columns = ['video_id', 'video_title', 'channel_title', 'view_count', \n",
    "                           'like_count', 'total_comments', 'duration_minutes',\n",
    "                           'comments_collected', 'total_comment_likes', 'avg_comment_likes', 'published_at']\n",
    "    \n",
    "    video_summary_csv = 'youtube_war_ukraine_video_summary_5.csv'\n",
    "    video_summary.to_csv(video_summary_csv, index=False, encoding='utf-8')\n",
    "    print(f\"💾 Summary video salvato come: {video_summary_csv}\")\n",
    "\n",
    "print(f\"\\n✨ Elaborazione completata!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
