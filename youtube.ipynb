{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3987ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- Configuration ---\n",
    "API_KEY = \"AIzaSyBlUpDZZ4gYI__pCKaI-I-XTiq2q_KCsQY\"  # Inserisci la tua API key nel file .env\n",
    "query = 'war ukraine'  # Puoi anche usare 'zelensky trump' per AND search\n",
    "max_results_per_search = 50  # Max 50 per richiesta\n",
    "max_videos = 2000  # Totale video da processare\n",
    "output_json = 'youtube_war_ukraine_2.json'\n",
    "\n",
    "# --- FILTRI TEMPORALI ---\n",
    "# Puoi impostare range temporali specifici (formato ISO 8601: YYYY-MM-DDTHH:MM:SSZ)\n",
    "published_after = '2024-03-01T00:00:00Z'  # Inizio range\n",
    "published_before = '2025-07-01T23:59:59Z'  # Fine range\n",
    "\n",
    "# --- SETTINGS ---\n",
    "request_delay = 1.0  # Secondi tra le richieste per rispettare rate limits\n",
    "comment_score_min = 5  # Score minimo per i commenti\n",
    "max_comments_per_video = 200  # Max commenti per video per risparmiare quota\n",
    "\n",
    "def initialize_youtube_api():\n",
    "    \"\"\"Inizializza il client YouTube API\"\"\"\n",
    "    if not API_KEY:\n",
    "        print(\"‚ùå Errore: YOUTUBE_API_KEY non trovata nel file .env\")\n",
    "        exit(1)\n",
    "    \n",
    "    try:\n",
    "        youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "        print(\"‚úÖ YouTube API inizializzata con successo!\")\n",
    "        return youtube\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore nell'inizializzare YouTube API: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "def search_videos(youtube, query, published_after=None, published_before=None, max_results=50, page_token=None):\n",
    "    \"\"\"Cerca video con filtri temporali\"\"\"\n",
    "    try:\n",
    "        search_params = {\n",
    "            'q': query,\n",
    "            'part': 'id,snippet',\n",
    "            'type': 'video',\n",
    "            'maxResults': max_results,\n",
    "            'order': 'date',  # Ordina per data\n",
    "            'regionCode': 'US'  # Puoi cambiare in 'IT' per risultati italiani\n",
    "        }\n",
    "        \n",
    "        # Aggiungi filtri temporali se specificati\n",
    "        if published_after:\n",
    "            search_params['publishedAfter'] = published_after\n",
    "        if published_before:\n",
    "            search_params['publishedBefore'] = published_before\n",
    "        if page_token:\n",
    "            search_params['pageToken'] = page_token\n",
    "            \n",
    "        response = youtube.search().list(**search_params).execute()\n",
    "        return response\n",
    "    \n",
    "    except HttpError as e:\n",
    "        print(f\"‚ùå Errore HTTP nella ricerca: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore generico nella ricerca: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_video_details(youtube, video_ids):\n",
    "    \"\"\"Ottieni dettagli dei video (statistiche, durata, etc.)\"\"\"\n",
    "    try:\n",
    "        response = youtube.videos().list(\n",
    "            part='statistics,contentDetails,snippet',\n",
    "            id=','.join(video_ids)\n",
    "        ).execute()\n",
    "        return response\n",
    "    except HttpError as e:\n",
    "        print(f\"‚ùå Errore nell'ottenere dettagli video: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_video_comments(youtube, video_id, max_results=100):\n",
    "    \"\"\"Ottieni commenti di un video con paginazione\"\"\"\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "    \n",
    "    try:\n",
    "        while len(comments) < max_results:\n",
    "            # Calcola quanti commenti mancano\n",
    "            remaining = max_results - len(comments)\n",
    "            per_page = min(100, remaining)  # YouTube max 100 per richiesta\n",
    "            \n",
    "            request_params = {\n",
    "                'part': 'snippet,replies',\n",
    "                'videoId': video_id,\n",
    "                'maxResults': per_page,\n",
    "                'order': 'relevance',  # Oppure 'time' per cronologico\n",
    "                'textFormat': 'plainText'\n",
    "            }\n",
    "            \n",
    "            if next_page_token:\n",
    "                request_params['pageToken'] = next_page_token\n",
    "            \n",
    "            response = youtube.commentThreads().list(**request_params).execute()\n",
    "            \n",
    "            for item in response['items']:\n",
    "                comment = item['snippet']['topLevelComment']['snippet']\n",
    "                \n",
    "                # Filtra per score minimo\n",
    "                if comment.get('likeCount', 0) >= comment_score_min:\n",
    "                    comment_data = {\n",
    "                        'author': comment.get('authorDisplayName', '[Unknown]'),\n",
    "                        'text': comment.get('textDisplay', ''),\n",
    "                        'like_count': comment.get('likeCount', 0),\n",
    "                        'published_at': comment.get('publishedAt', ''),\n",
    "                        'updated_at': comment.get('updatedAt', '')\n",
    "                    }\n",
    "                    \n",
    "                    # Aggiungi replies se presenti\n",
    "                    if 'replies' in item:\n",
    "                        replies = []\n",
    "                        for reply in item['replies']['comments']:\n",
    "                            reply_snippet = reply['snippet']\n",
    "                            if reply_snippet.get('likeCount', 0) >= comment_score_min:\n",
    "                                replies.append({\n",
    "                                    'author': reply_snippet.get('authorDisplayName', '[Unknown]'),\n",
    "                                    'text': reply_snippet.get('textDisplay', ''),\n",
    "                                    'like_count': reply_snippet.get('likeCount', 0),\n",
    "                                    'published_at': reply_snippet.get('publishedAt', '')\n",
    "                                })\n",
    "                        comment_data['replies'] = replies\n",
    "                    \n",
    "                    comments.append(comment_data)\n",
    "            \n",
    "            # Controlla se ci sono altre pagine\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "                \n",
    "            # Pausa tra le richieste\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    except HttpError as e:\n",
    "        if 'commentsDisabled' in str(e):\n",
    "            print(f\"      ‚ÑπÔ∏è Commenti disabilitati per video {video_id}\")\n",
    "        else:\n",
    "            print(f\"      ‚ö†Ô∏è Errore nell'ottenere commenti per {video_id}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ö†Ô∏è Errore generico commenti per {video_id}: {e}\")\n",
    "    \n",
    "    return comments\n",
    "\n",
    "def main():\n",
    "    print(\"üé• YouTube Data Scraper - Avvio raccolta dati...\")\n",
    "    print(f\"üîç Query: '{query}'\")\n",
    "    print(f\"üìÖ Range temporale: {published_after} -> {published_before}\")\n",
    "    \n",
    "    # Inizializza API\n",
    "    youtube = initialize_youtube_api()\n",
    "    \n",
    "    all_data = []\n",
    "    total_videos = 0\n",
    "    total_comments = 0\n",
    "    next_page_token = None\n",
    "    page_number = 1\n",
    "    \n",
    "    # Stima quota usage\n",
    "    estimated_quota = 0\n",
    "    \n",
    "    while total_videos < max_videos:\n",
    "        print(f\"\\nüìÑ Pagina {page_number} - Ricerca video...\")\n",
    "        \n",
    "        # Calcola quanti video mancano\n",
    "        remaining_videos = max_videos - total_videos\n",
    "        search_limit = min(max_results_per_search, remaining_videos)\n",
    "        \n",
    "        # Cerca video\n",
    "        search_response = search_videos(\n",
    "            youtube, query, published_after, published_before, \n",
    "            search_limit, next_page_token\n",
    "        )\n",
    "        \n",
    "        if not search_response or not search_response.get('items'):\n",
    "            print(\"   ‚ÑπÔ∏è Nessun video trovato o fine risultati\")\n",
    "            break\n",
    "        \n",
    "        estimated_quota += 100  # Costo search\n",
    "        videos = search_response['items']\n",
    "        print(f\"   üìπ Trovati {len(videos)} video\")\n",
    "        \n",
    "        # Ottieni dettagli video (statistiche)\n",
    "        video_ids = [video['id']['videoId'] for video in videos]\n",
    "        video_details_response = get_video_details(youtube, video_ids)\n",
    "        estimated_quota += 1  # Costo video details\n",
    "        \n",
    "        # Crea mappa per accesso rapido ai dettagli\n",
    "        video_details_map = {}\n",
    "        if video_details_response:\n",
    "            for detail in video_details_response['items']:\n",
    "                video_details_map[detail['id']] = detail\n",
    "        \n",
    "        page_videos = 0\n",
    "        page_comments = 0\n",
    "        \n",
    "        # Processa ogni video\n",
    "        for video in videos:\n",
    "            video_id = video['id']['videoId']\n",
    "            snippet = video['snippet']\n",
    "            \n",
    "            # Ottieni dettagli aggiuntivi\n",
    "            details = video_details_map.get(video_id, {})\n",
    "            stats = details.get('statistics', {})\n",
    "            content_details = details.get('contentDetails', {})\n",
    "            \n",
    "            print(f\"   üé¨ Processando: {snippet['title'][:50]}...\")\n",
    "            \n",
    "            # Ottieni commenti\n",
    "            comments = get_video_comments(youtube, video_id, max_comments_per_video)\n",
    "            estimated_quota += max(1, len(comments) // 100)  # Stima quota commenti\n",
    "            \n",
    "            # Costruisci record video\n",
    "            video_record = {\n",
    "                'page_number': page_number,\n",
    "                'video_id': video_id,\n",
    "                'title': snippet['title'],\n",
    "                'description': snippet.get('description', '')[:500],  # Primi 500 char\n",
    "                'channel_title': snippet['channelTitle'],\n",
    "                'channel_id': snippet['channelId'],\n",
    "                'published_at': snippet['publishedAt'],\n",
    "                'thumbnail_url': snippet['thumbnails']['high']['url'] if 'high' in snippet['thumbnails'] else '',\n",
    "                \n",
    "                # Statistiche\n",
    "                'view_count': int(stats.get('viewCount', 0)),\n",
    "                'like_count': int(stats.get('likeCount', 0)),\n",
    "                'comment_count': int(stats.get('commentCount', 0)),\n",
    "                'duration': content_details.get('duration', ''),\n",
    "                \n",
    "                # Commenti raccolti\n",
    "                'comments': comments,\n",
    "                'comments_collected': len(comments)\n",
    "            }\n",
    "            \n",
    "            all_data.append(video_record)\n",
    "            page_videos += 1\n",
    "            page_comments += len(comments)\n",
    "            \n",
    "            # Piccola pausa tra i video\n",
    "            time.sleep(0.2)\n",
    "        \n",
    "        total_videos += page_videos\n",
    "        total_comments += page_comments\n",
    "        \n",
    "        print(f\"   ‚úÖ {page_videos} video, {page_comments} commenti raccolti\")\n",
    "        print(f\"   üìä Totale: {total_videos} video, {total_comments} commenti\")\n",
    "        print(f\"   üìà Quota stimata usata: {estimated_quota}/10000\")\n",
    "        \n",
    "        # Controlla se ci sono altre pagine\n",
    "        next_page_token = search_response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            print(\"   ‚ÑπÔ∏è Non ci sono pi√π pagine disponibili\")\n",
    "            break\n",
    "        \n",
    "        page_number += 1\n",
    "        \n",
    "        # Pausa tra le pagine per rispettare rate limits\n",
    "        time.sleep(request_delay)\n",
    "        \n",
    "        # Salva progressi ogni 5 pagine\n",
    "        if page_number % 5 == 0:\n",
    "            print(f\"   üíæ Salvataggio progressi...\")\n",
    "            with open(f\"temp_{output_json}\", 'w', encoding='utf-8') as f:\n",
    "                json.dump(all_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Salvataggio finale\n",
    "    print(f\"\\nüíæ Salvataggio finale in {output_json}...\")\n",
    "    with open(output_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Statistiche finali\n",
    "    print(f\"\\nüéâ COMPLETATO!\")\n",
    "    print(f\"üìä Statistiche finali:\")\n",
    "    print(f\"   üìÑ Pagine processate: {page_number}\")\n",
    "    print(f\"   üé¨ Video totali: {total_videos}\")\n",
    "    print(f\"   üí¨ Commenti totali: {total_comments}\")\n",
    "    print(f\"   üìà Quota stimata usata: {estimated_quota}/10000 ({(estimated_quota/10000)*100:.1f}%)\")\n",
    "    print(f\"   üìÑ File salvato: {output_json}\")\n",
    "    \n",
    "    if total_videos > 0:\n",
    "        print(f\"   ‚è±Ô∏è Media commenti/video: {total_comments/total_videos:.1f}\")\n",
    "    \n",
    "    # Rimuovi file temporaneo\n",
    "    temp_file = f\"temp_{output_json}\"\n",
    "    if os.path.exists(temp_file):\n",
    "        os.remove(temp_file)\n",
    "        print(f\"üóëÔ∏è File temporaneo rimosso\")\n",
    "    \n",
    "    print(f\"\\n‚ú® Raccolta completata!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16176ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Caricamento del file JSON ---\n",
    "with open('youtube_war_ukraine_2.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# --- Statistiche ---\n",
    "num_videos = len(data)\n",
    "num_comments = sum(video['comments_collected'] for video in data)\n",
    "total_views = sum(video['view_count'] for video in data)\n",
    "total_likes = sum(video['like_count'] for video in data)\n",
    "\n",
    "print(f\"üé• Numero totale di video: {num_videos}\")\n",
    "print(f\"üí¨ Numero totale di commenti raccolti: {num_comments}\")\n",
    "print(f\"üëÄ Visualizzazioni totali: {total_views:,}\")\n",
    "print(f\"üëç Like totali: {total_likes:,}\")\n",
    "\n",
    "if num_videos > 0:\n",
    "    print(f\"üìä Media commenti per video: {num_comments/num_videos:.1f}\")\n",
    "    print(f\"üìä Media visualizzazioni per video: {total_views/num_videos:,.0f}\")\n",
    "\n",
    "# --- Creazione del DataFrame ---\n",
    "rows = []\n",
    "\n",
    "for video in data:\n",
    "    video_id = video['video_id']\n",
    "    video_title = video['title']\n",
    "    channel_title = video['channel_title']\n",
    "    channel_id = video['channel_id']\n",
    "    published_at = video['published_at']\n",
    "    view_count = video['view_count']\n",
    "    like_count = video['like_count']\n",
    "    comment_count = video['comment_count']\n",
    "    duration = video['duration']\n",
    "    description = video['description']\n",
    "    \n",
    "    # Se il video non ha commenti, aggiungi comunque una riga per il video\n",
    "    if not video['comments']:\n",
    "        rows.append({\n",
    "            'video_id': video_id,\n",
    "            'video_title': video_title,\n",
    "            'channel_title': channel_title,\n",
    "            'channel_id': channel_id,\n",
    "            'video_published_at': published_at,\n",
    "            'video_view_count': view_count,\n",
    "            'video_like_count': like_count,\n",
    "            'video_comment_count': comment_count,\n",
    "            'video_duration': duration,\n",
    "            'video_description': description[:200] + '...' if len(description) > 200 else description,\n",
    "            \n",
    "            # Campi commento vuoti\n",
    "            'comment_author': None,\n",
    "            'comment_text': None,\n",
    "            'comment_like_count': None,\n",
    "            'comment_published_at': None,\n",
    "            'comment_updated_at': None,\n",
    "            'comment_replies_count': None,\n",
    "            'is_reply': False\n",
    "        })\n",
    "    else:\n",
    "        # Processa ogni commento\n",
    "        for comment in video['comments']:\n",
    "            # Commento principale\n",
    "            rows.append({\n",
    "                'video_id': video_id,\n",
    "                'video_title': video_title,\n",
    "                'channel_title': channel_title,\n",
    "                'channel_id': channel_id,\n",
    "                'video_published_at': published_at,\n",
    "                'video_view_count': view_count,\n",
    "                'video_like_count': like_count,\n",
    "                'video_comment_count': comment_count,\n",
    "                'video_duration': duration,\n",
    "                'video_description': description[:200] + '...' if len(description) > 200 else description,\n",
    "                \n",
    "                # Dati commento\n",
    "                'comment_author': comment['author'],\n",
    "                'comment_text': comment['text'],\n",
    "                'comment_like_count': comment['like_count'],\n",
    "                'comment_published_at': comment['published_at'],\n",
    "                'comment_updated_at': comment['updated_at'],\n",
    "                'comment_replies_count': len(comment.get('replies', [])),\n",
    "                'is_reply': False\n",
    "            })\n",
    "            \n",
    "            # Processa le risposte se presenti\n",
    "            if 'replies' in comment and comment['replies']:\n",
    "                for reply in comment['replies']:\n",
    "                    rows.append({\n",
    "                        'video_id': video_id,\n",
    "                        'video_title': video_title,\n",
    "                        'channel_title': channel_title,\n",
    "                        'channel_id': channel_id,\n",
    "                        'video_published_at': published_at,\n",
    "                        'video_view_count': view_count,\n",
    "                        'video_like_count': like_count,\n",
    "                        'video_comment_count': comment_count,\n",
    "                        'video_duration': duration,\n",
    "                        'video_description': description[:200] + '...' if len(description) > 200 else description,\n",
    "                        \n",
    "                        # Dati reply\n",
    "                        'comment_author': reply['author'],\n",
    "                        'comment_text': reply['text'],\n",
    "                        'comment_like_count': reply['like_count'],\n",
    "                        'comment_published_at': reply['published_at'],\n",
    "                        'comment_updated_at': reply.get('updated_at', reply['published_at']),\n",
    "                        'comment_replies_count': 0,  # Le risposte non hanno sotto-risposte\n",
    "                        'is_reply': True\n",
    "                    })\n",
    "\n",
    "# Crea DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# --- Elaborazioni aggiuntive ---\n",
    "if not df.empty:\n",
    "    # Converti le date in datetime per analisi temporali\n",
    "    df['video_published_at'] = pd.to_datetime(df['video_published_at'])\n",
    "    df['comment_published_at'] = pd.to_datetime(df['comment_published_at'])\n",
    "\n",
    "    # Aggiungi questa riga per rimuovere timezone info\n",
    "    df['video_published_at'] = df['video_published_at'].dt.tz_localize(None)\n",
    "    \n",
    "    # Aggiungi colonne derivate utili per l'analisi\n",
    "    df['video_age_days'] = (datetime.now() - df['video_published_at']).dt.days\n",
    "    df['comment_length'] = df['comment_text'].str.len()\n",
    "    \n",
    "    # Estrai durata in secondi (da formato PT1M30S)\n",
    "    def parse_duration(duration_str):\n",
    "        if not duration_str or duration_str == '':\n",
    "            return 0\n",
    "        try:\n",
    "            # Rimuovi PT e splitta per M e S\n",
    "            duration_str = duration_str.replace('PT', '')\n",
    "            minutes = 0\n",
    "            seconds = 0\n",
    "            \n",
    "            if 'H' in duration_str:\n",
    "                parts = duration_str.split('H')\n",
    "                hours = int(parts[0])\n",
    "                duration_str = parts[1]\n",
    "                minutes += hours * 60\n",
    "            \n",
    "            if 'M' in duration_str:\n",
    "                parts = duration_str.split('M')\n",
    "                minutes += int(parts[0])\n",
    "                duration_str = parts[1]\n",
    "            \n",
    "            if 'S' in duration_str:\n",
    "                seconds = int(duration_str.replace('S', ''))\n",
    "            \n",
    "            return minutes * 60 + seconds\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    df['video_duration_seconds'] = df['video_duration'].apply(parse_duration)\n",
    "    df['video_duration_minutes'] = df['video_duration_seconds'] / 60\n",
    "\n",
    "# --- Visualizzazione del DataFrame ---\n",
    "print(f\"\\nüßæ DataFrame creato con {len(df)} righe\")\n",
    "print(f\"üìä Colonne disponibili: {list(df.columns)}\")\n",
    "\n",
    "if not df.empty:\n",
    "    print(\"\\nüìã Esempio del DataFrame:\")\n",
    "    print(df[['video_title', 'channel_title', 'comment_author', 'comment_like_count', 'is_reply']].head())\n",
    "    \n",
    "    print(f\"\\nüìà Statistiche rapide:\")\n",
    "    print(f\"   üé¨ Video unici: {df['video_id'].nunique()}\")\n",
    "    print(f\"   üì∫ Canali unici: {df['channel_id'].nunique()}\")\n",
    "    print(f\"   üë§ Autori commenti unici: {df['comment_author'].nunique()}\")\n",
    "    print(f\"   üí¨ Commenti principali: {len(df[df['is_reply'] == False])}\")\n",
    "    print(f\"   üîÑ Risposte: {len(df[df['is_reply'] == True])}\")\n",
    "    \n",
    "    if df['comment_like_count'].notna().any():\n",
    "        print(f\"   üëç Like medio per commento: {df['comment_like_count'].mean():.1f}\")\n",
    "        print(f\"   üëç Commento con pi√π like: {df['comment_like_count'].max()}\")\n",
    "    \n",
    "    # Top canali per numero di video\n",
    "    print(f\"\\nüèÜ Top 5 canali per numero di video:\")\n",
    "    top_channels = df.groupby('channel_title')['video_id'].nunique().sort_values(ascending=False).head()\n",
    "    for channel, count in top_channels.items():\n",
    "        print(f\"   üì∫ {channel}: {count} video\")\n",
    "\n",
    "# --- Salvataggio ---\n",
    "if not df.empty:\n",
    "    # Salva come CSV\n",
    "    csv_filename = 'youtube_war_ukraine_data_2.csv'\n",
    "    df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "    print(f\"\\nüíæ DataFrame salvato come: {csv_filename}\")\n",
    "    \n",
    "    # Salva anche un dataset solo commenti (senza video senza commenti)\n",
    "    df_comments_only = df[df['comment_text'].notna()]\n",
    "    if not df_comments_only.empty:\n",
    "        comments_csv = 'youtube_war_ukraine_comments_only_2.csv'\n",
    "        df_comments_only.to_csv(comments_csv, index=False, encoding='utf-8')\n",
    "        print(f\"üíæ Solo commenti salvati come: {comments_csv}\")\n",
    "        \n",
    "    # Crea anche un summary dei video\n",
    "    video_summary = df.groupby(['video_id', 'video_title', 'channel_title']).agg({\n",
    "        'video_view_count': 'first',\n",
    "        'video_like_count': 'first',\n",
    "        'video_comment_count': 'first',\n",
    "        'video_duration_minutes': 'first',\n",
    "        'comment_like_count': ['count', 'sum', 'mean'],\n",
    "        'video_published_at': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten column names\n",
    "    video_summary.columns = ['video_id', 'video_title', 'channel_title', 'view_count', \n",
    "                           'like_count', 'total_comments', 'duration_minutes',\n",
    "                           'comments_collected', 'total_comment_likes', 'avg_comment_likes', 'published_at']\n",
    "    \n",
    "    video_summary_csv = 'youtube_war_ukraine_video_summary_2.csv'\n",
    "    video_summary.to_csv(video_summary_csv, index=False, encoding='utf-8')\n",
    "    print(f\"üíæ Summary video salvato come: {video_summary_csv}\")\n",
    "\n",
    "print(f\"\\n‚ú® Elaborazione completata!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
